{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\antoi\\Desktop\\thesis\\1_2_biosyn_replicate\\git_repo_final\\myenv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "100%|██████████| 90599/90599 [00:00<00:00, 1436449.35it/s]\n",
      "100%|██████████| 691/691 [00:00<00:00, 6252.94it/s]\n"
     ]
    }
   ],
   "source": [
    "from biosyn.dataloader import load_dictionary, load_queries\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "import torch\n",
    "TRAIN_DICT_PATH = \"./data/data-ncbi-fair/train_dictionary.txt\"\n",
    "TRAIN_DIR = \"./data/data-ncbi-fair/traindev\"\n",
    "\n",
    "train_dictionary  = load_dictionary(dict_path=TRAIN_DICT_PATH)\n",
    "train_queries  = load_queries(data_dir=TRAIN_DIR, filter_composite=False, filter_duplicates=False, filter_cuiless=True)\n",
    "\n",
    "train_dictionary = train_dictionary[:50]\n",
    "train_queries = train_queries[:10]\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('dmis-lab/biobert-base-cased-v1.1')\n",
    "encoder = AutoModel.from_pretrained('dmis-lab/biobert-base-cased-v1.1')\n",
    "\n",
    "\n",
    "max_length = 25\n",
    "\n",
    "\n",
    "query_names = [row[0] for row in train_queries]\n",
    "dict_names = [row[0] for row in train_dictionary]\n",
    "topk = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import default_data_collator\n",
    "\n",
    "class NamesDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings):\n",
    "        self.encodings = encodings\n",
    "    def __getitem__(self,idx):\n",
    "        return {key: torch.tensor(val[idx]) for key,val in self.encodings.items()}\n",
    "    def __len__(self):\n",
    "        return len(self.encodings.input_ids)\n",
    "\n",
    "\n",
    "def embed_dense(names):\n",
    "        encoder.eval()\n",
    "        batch_size = 128\n",
    "        dense_embeds = []\n",
    "        if isinstance(names, np.ndarray):\n",
    "            names = names.tolist()\n",
    "        name_encodings = tokenizer(names, padding=\"max_length\", max_length=max_length, truncation=True, return_tensors=\"pt\")\n",
    "\n",
    "        name_dataset = NamesDataset(name_encodings)\n",
    "        name_dataloader = DataLoader(name_dataset, shuffle=False, collate_fn=default_data_collator, batch_size=batch_size)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch in name_dataloader:\n",
    "                outputs = encoder(**batch)\n",
    "                batch_dense_embeds = outputs[0][:,0].cpu().detach().numpy() # [CLS] representations\n",
    "                dense_embeds.append(batch_dense_embeds)\n",
    "        dense_embeds = np.concatenate(dense_embeds, axis=0)\n",
    "        return dense_embeds\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\antoi\\AppData\\Local\\Temp\\ipykernel_23036\\248688504.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return {key: torch.tensor(val[idx]) for key,val in self.encodings.items()}\n"
     ]
    }
   ],
   "source": [
    "dict_embs = embed_dense(names=dict_names).astype(\"float32\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 768])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topk_cand_idxs = [0,10,5,3]\n",
    "cands_embs_1 = dict_embs[topk_cand_idxs]\n",
    "cands_embs_1 = torch.from_numpy( cands_embs_1.astype(np.float32, copy=False) )\n",
    "cands_embs_1.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "        # candidate_embeds = self.dict_embs[topk_cand_idxs]\n",
    "        B, K  = topk_cand_idxs.shape\n",
    "        flat = topk_cand_idxs.reshape(-1)\n",
    "        candidate_embs = self.dict_embs.index_select(0, flat).reshape(B, K, -1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 768])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_dict_names_tokens= tokenizer(dict_names, max_length=max_length,padding='max_length', truncation=True, return_tensors='pt')\n",
    "\n",
    "\n",
    "\n",
    "cand_idxs_tensor = torch.as_tensor(topk_cand_idxs, dtype=torch.long)\n",
    "cand_tokens = {\n",
    "    k: v.index_select(0, cand_idxs_tensor)\n",
    "    for k, v in all_dict_names_tokens.items()\n",
    "    if isinstance(v, torch.Tensor)\n",
    "}\n",
    "\n",
    "candidate_embeds = encoder(\n",
    "            input_ids=cand_tokens['input_ids'].reshape(-1, max_length),\n",
    "            attention_mask=cand_tokens['attention_mask'].reshape(-1, max_length)\n",
    "        )\n",
    "cand_embs_2 = candidate_embeds[0][:,0].reshape(topk, -1) # [topk, hidden]\n",
    "cand_embs_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\antoi\\AppData\\Local\\Temp\\ipykernel_23036\\923541028.py:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  are_equal_elementwise = torch.all(torch.tensor(cands_embs_1) == cand_embs_2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(False)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "are_equal_elementwise = torch.all(torch.tensor(cands_embs_1) == cand_embs_2)\n",
    "are_equal_elementwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True torch.float32 torch.float32\n",
      "Number of differing elements: 2826\n",
      "First few differing indices (row, col):\n",
      "tensor([[0, 0],\n",
      "        [0, 1],\n",
      "        [0, 2],\n",
      "        [0, 3],\n",
      "        [0, 4],\n",
      "        [0, 5],\n",
      "        [0, 6],\n",
      "        [0, 7],\n",
      "        [0, 8],\n",
      "        [0, 9]])\n",
      "[0, 0]  a=0.37157875299453735   b=0.3715788722038269\n",
      "[0, 1]  a=0.23373164236545563   b=0.23373158276081085\n",
      "[0, 2]  a=-0.2861679196357727   b=-0.2861679494380951\n",
      "[0, 3]  a=-0.04448281601071358   b=-0.044482868164777756\n",
      "[0, 4]  a=-0.05088842287659645   b=-0.050888314843177795\n",
      "Differences per row: [719, 724, 673, 710]\n",
      "Max |a-b|: 9.5367431640625e-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\antoi\\AppData\\Local\\Temp\\ipykernel_23036\\896783195.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  a = torch.tensor(cands_embs_1)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "a = torch.tensor(cands_embs_1)\n",
    "b= cand_embs_2\n",
    "\n",
    "# a, b: shape (4, 768)\n",
    "\n",
    "# 1) Sanity checks\n",
    "print(a.shape == b.shape, a.dtype, b.dtype)\n",
    "\n",
    "# 2) Elementwise difference mask (exact equality for non-floats)\n",
    "if torch.is_floating_point(a) and torch.is_floating_point(b):\n",
    "    # treat NaNs at same spots as equal; flag others via isclose\n",
    "    same_nan = torch.isnan(a) & torch.isnan(b)\n",
    "    close = torch.isclose(a, b, rtol=0.0, atol=0.0)  # exact values for floats\n",
    "    diff_mask = ~(close | same_nan)\n",
    "else:\n",
    "    diff_mask = a != b\n",
    "\n",
    "num_diff = diff_mask.sum().item()\n",
    "print(f\"Number of differing elements: {num_diff}\")\n",
    "\n",
    "# 3) Indices of differences\n",
    "idx = diff_mask.nonzero(as_tuple=False)  # shape (num_diff, 2), columns: [row, col]\n",
    "print(\"First few differing indices (row, col):\")\n",
    "print(idx[:10])\n",
    "\n",
    "# 4) Inspect values at those spots\n",
    "for r, c in idx[:5]:  # show first 5\n",
    "    r = r.item(); c = c.item()\n",
    "    print(f\"[{r}, {c}]  a={a[r, c].item()}   b={b[r, c].item()}\")\n",
    "\n",
    "# 5) Per-row counts (handy for (4, 768))\n",
    "per_row = diff_mask.sum(dim=1)\n",
    "print(\"Differences per row:\", per_row.tolist())\n",
    "\n",
    "# 6) Magnitude summary (useful for floats)\n",
    "if torch.is_floating_point(a) and torch.is_floating_point(b):\n",
    "    max_abs = (a - b).abs().max().item()\n",
    "    print(\"Max |a-b|:\", max_abs)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
